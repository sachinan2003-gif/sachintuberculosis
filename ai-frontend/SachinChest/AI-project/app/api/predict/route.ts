import { type NextRequest, NextResponse } from "next/server"

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const file = formData.get("file") as File

    if (!file) {
      return NextResponse.json({ error: "No file provided" }, { status: 400 })
    }

    // Validate file type
    if (!file.type.startsWith("image/")) {
      return NextResponse.json({ error: "Invalid file type. Please upload an image." }, { status: 400 })
    }

    // Validate file size (max 10MB)
    if (file.size > 10 * 1024 * 1024) {
      return NextResponse.json({ error: "File too large. Maximum size is 10MB." }, { status: 400 })
    }

    // Convert file to buffer
    const bytes = await file.arrayBuffer()
    const buffer = Buffer.from(bytes)

    // For now, return a mock prediction
    // In a real implementation, this would call the Python AI model
    const mockPrediction = {
      result: Math.random() > 0.5 ? "TB" : ("Normal" as "TB" | "Normal"),
      confidence: 0.85 + Math.random() * 0.14, // Random confidence between 0.85-0.99
      heatmap: generateMockHeatmap(), // Mock base64 heatmap
    }

    return NextResponse.json(mockPrediction)
  } catch (error) {
    console.error("Prediction error:", error)
    return NextResponse.json({ error: "Internal server error" }, { status: 500 })
  }
}

// Generate a mock base64 heatmap for demonstration
function generateMockHeatmap(): string {
  // This is a simple 1x1 pixel red image as base64
  // In a real implementation, this would be generated by the AI model
  return "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg=="
}
